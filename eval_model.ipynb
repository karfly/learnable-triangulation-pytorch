{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "formed-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "annual-fireplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import shutil\n",
    "import argparse\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from itertools import islice\n",
    "import pickle\n",
    "import copy\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "from mvn.models.triangulation import RANSACTriangulationNet, AlgebraicTriangulationNet, VolumetricTriangulationNet\n",
    "from mvn.models.loss import KeypointsMSELoss, KeypointsMSESmoothLoss, KeypointsMAELoss, KeypointsL2Loss, VolumetricCELoss, element_weighted_loss\n",
    "\n",
    "from mvn.utils import img, multiview, op, vis, misc, cfg\n",
    "from mvn.datasets import human36m\n",
    "from mvn.datasets import utils as dataset_utils\n",
    "from mvn.utils.multiview import project_3d_points_to_image_plane_without_distortion\n",
    "\n",
    "from mvn.utils.minimon import MiniMon\n",
    "from mvn.utils.misc import normalize_transformation, flush_cache\n",
    "from mvn.utils.dicts import NestedNamespace\n",
    "\n",
    "from train import setup_dataloaders, setup_experiment\n",
    "\n",
    "\n",
    "flush_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "latter-advance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# available GPUs: 1\n",
      "estimating dataset size ...\n",
      "  ... available subjects ['S1', 'S6', 'S7', 'S8'] and subsampling 1/10000 => 12 available frames\n",
      "estimating dataset size ...\n",
      "  ... available subjects ['S9', 'S11'] and subsampling 1/100 => 22 available frames\n",
      "  training dataset length: 12\n",
      "  validation dataset length: 5\n"
     ]
    }
   ],
   "source": [
    "def get_args():\n",
    "    args = NestedNamespace(\n",
    "        dict(\n",
    "            config='experiments/human36m/train/human36m_alg.yaml',\n",
    "            eval=False,\n",
    "            eval_dataset='val',\n",
    "            local_rank=None, logdir='/home/stefano/_tmp/logs',\n",
    "            seed=42\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print('# available GPUs: {:d}'.format(torch.cuda.device_count()))\n",
    "    \n",
    "    return args\n",
    "\n",
    "\n",
    "def get_config(args):\n",
    "    config = cfg.load_config(args.config)\n",
    "\n",
    "    config.image_shape = [128, 128]\n",
    "    config.debug.write_imgs = True\n",
    "    config.debug.img_out = '/home/stefano/_tmp/logs/imgs'\n",
    "    config.debug.dump_checkpoints = False\n",
    "\n",
    "    config.opt.n_epochs = 2\n",
    "    config.opt.n_iters_per_epoch = config.opt.n_objects_per_epoch // config.opt.batch_size\n",
    "    \n",
    "    config.opt.torch_anomaly_detection = False\n",
    "\n",
    "    config.opt.batch_size = 8\n",
    "    config.opt.val_batch_size = 16\n",
    "\n",
    "    data_folder = '/home/stefano/_tmp/data/'\n",
    "\n",
    "    config.model.triangulate_in_world_space = False  # in cam space\n",
    "    config.model.init_weights = False  # there is no point in loading full module with a shitty GPU\n",
    "    config.model.checkpoint = data_folder + 'weights_alg.pth'  #  + 'weights_vol.pth'\n",
    "    config.model.backbone.checkpoint = data_folder + 'pose_resnet_4.5_pixels_human36m.pth'\n",
    "    config.model.backbone.init_weights = config.model.init_weights\n",
    "    config.model.backbone.num_layers = 18  # very small BB\n",
    "    config.model.backbone.num_deconv_filters = 32\n",
    "\n",
    "    config.dataset.train.h36m_root = data_folder + 'processed/'\n",
    "    config.dataset.train.labels_path = data_folder + 'human36m-multiview-labels-GTbboxes.npy'\n",
    "    config.dataset.train.retain_every_n_frames_in_train = 10000  # 12 images when in full dataset\n",
    "    config.dataset.train.num_workers = 2\n",
    "\n",
    "    config.dataset.val.h36m_root = config.dataset.train.h36m_root  # the same! WTF!\n",
    "    config.dataset.val.labels_path = config.dataset.train.labels_path  # the same! WTF!\n",
    "    config.dataset.val.retain_every_n_frames_in_test = 500  # 5 images when in full dataset\n",
    "    config.dataset.val.num_workers = 2\n",
    "    \n",
    "    return config\n",
    "\n",
    "\n",
    "def build_labels(f_path, retain_every_n_frames, allowed_subjects=['S1', 'S6', 'S7', 'S8']):\n",
    "    print('estimating dataset size ...')\n",
    "    labels = np.load(f_path, allow_pickle=True).item()\n",
    "    \n",
    "    subjects = [\n",
    "        labels['subject_names'].index(x)\n",
    "        for x in allowed_subjects  # todo solve missing images in 'S5'\n",
    "    ]\n",
    "    \n",
    "    mask = np.isin(labels['table']['subject_idx'], subjects, assume_unique=True)\n",
    "    indices = np.nonzero(mask)[0][::retain_every_n_frames]\n",
    "    \n",
    "    print('  ... available subjects {} and subsampling 1/{:d} => {:d} available frames'.format(\n",
    "        allowed_subjects,\n",
    "        retain_every_n_frames,\n",
    "        len(indices)\n",
    "    ))\n",
    "    \n",
    "    return labels, mask, indices\n",
    "\n",
    "\n",
    "def build_env(config, device):\n",
    "    model = {\n",
    "        \"ransac\": RANSACTriangulationNet,\n",
    "        \"alg\": AlgebraicTriangulationNet,\n",
    "        \"vol\": VolumetricTriangulationNet\n",
    "    }[config.model.name](config, device=device).to(device)\n",
    "\n",
    "    if config.model.init_weights:\n",
    "        state_dict = torch.load(config.model.checkpoint)\n",
    "        for key in list(state_dict.keys()):\n",
    "            new_key = key.replace(\"module.\", \"\")\n",
    "            state_dict[new_key] = state_dict.pop(key)\n",
    "\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "        print('Successfully loaded pretrained weights for whole model')\n",
    "    \n",
    "    criterion_class = {\n",
    "        \"MSE\": KeypointsMSELoss,\n",
    "        \"MSESmooth\": KeypointsMSESmoothLoss,\n",
    "        \"MAE\": KeypointsMAELoss\n",
    "    }[config.opt.criterion]\n",
    "\n",
    "    if config.opt.criterion == \"MSESmooth\":\n",
    "        criterion = criterion_class(config.opt.mse_smooth_threshold)\n",
    "    else:\n",
    "        criterion = criterion_class()\n",
    "\n",
    "    if config.model.name == \"vol\":\n",
    "        opt = torch.optim.Adam(\n",
    "            [\n",
    "                {\n",
    "                    'params': model.backbone.parameters()\n",
    "                },\n",
    "                {\n",
    "                    'params': model.process_features.parameters(),\n",
    "                    'lr': config.opt.process_features_lr if hasattr(config.opt, \"process_features_lr\") else config.opt.lr\n",
    "                },\n",
    "                {\n",
    "                    'params': model.volume_net.parameters(),\n",
    "                    'lr': config.opt.volume_net_lr if hasattr(config.opt, \"volume_net_lr\") else config.opt.lr\n",
    "                }\n",
    "            ],\n",
    "            lr=config.opt.lr\n",
    "        )\n",
    "    else:\n",
    "        opt = optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            lr=config.opt.lr\n",
    "        )\n",
    "    \n",
    "    return model, criterion, opt\n",
    "\n",
    "\n",
    "is_distributed = False\n",
    "master = True\n",
    "device = torch.device(0)\n",
    "    \n",
    "args = get_args()\n",
    "config = get_config(args)\n",
    "model, criterion, opt = build_env(config, torch.device(0))\n",
    "labels, mask, indices = build_labels(config.dataset.train.labels_path, 10000)\n",
    "labels, mask, indices = build_labels(config.dataset.train.labels_path, 100, allowed_subjects=['S9', 'S11'])\n",
    "\n",
    "train_dataloader, val_dataloader, train_sampler = setup_dataloaders(config, distributed_train=is_distributed)  # ~ 0 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dedicated-speech",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0 has started!\n",
      "  training batch iter 0 loss ~ 332.515\n",
      "  training batch iter 1 loss ~ 331.627\n",
      "  training MPJPE relative to pelvis: 758.561\n",
      "  eval MPJPE relative to pelvis: 471.035\n",
      "epoch    0 complete!\n",
      "epoch    1 has started!\n",
      "  training batch iter 0 loss ~ 323.806\n",
      "  training batch iter 1 loss ~ 286.375\n",
      "  training MPJPE relative to pelvis: 693.812\n",
      "  eval MPJPE relative to pelvis: 470.223\n",
      "epoch    1 complete!\n",
      "           calc loss x          4 ~        0.0 [min:        0.0,    max:        0.0,    last:        0.0]\n",
      "    evaluate results x          4 ~        0.0 [min:        0.0,    max:        0.0,    last:        0.0]\n",
      "lg: tri in cam space x          6 ~        0.0 [min:        0.0,    max:        0.0,    last:        0.0]\n",
      "       backward pass x          4 ~        0.1 [min:        0.0,    max:        0.1,    last:        0.0]\n",
      "       alg: backbone x          6 ~        0.1 [min:        0.0,    max:        0.5,    last:        0.0]\n",
      "        forward pass x          6 ~        0.1 [min:        0.0,    max:        0.5,    last:        0.0]\n",
      "oad first eval batch x          2 ~        0.4 [min:        0.4,    max:        0.5,    last:        0.4]\n",
      "ad first train batch x          2 ~        0.6 [min:        0.6,    max:        0.6,    last:        0.6]\n",
      "          eval epoch x          2 ~        3.3 [min:        3.2,    max:        3.3,    last:        3.2]\n",
      "         train epoch x          2 ~        7.3 [min:        7.1,    max:        7.5,    last:        7.1]\n",
      "    all times are in seconds\n"
     ]
    }
   ],
   "source": [
    "from train import one_epoch\n",
    "\n",
    "minimon = MiniMon()\n",
    "for epoch in range(config.opt.n_epochs):\n",
    "    # cannot use train_sampler.set_epoch since we're not distributed !\n",
    "    \n",
    "    f_out = 'epoch {:4d} has started!'\n",
    "    print(f_out.format(epoch))\n",
    "\n",
    "    minimon.enter()\n",
    "    one_epoch(model, criterion, opt, config, train_dataloader, device, epoch, minimon, is_train=True, master=master)\n",
    "    minimon.leave('train epoch')\n",
    "\n",
    "    minimon.enter()\n",
    "    one_epoch(model, criterion, opt, config, val_dataloader, device, epoch, minimon, is_train=False, master=master)\n",
    "    minimon.leave('eval epoch')\n",
    "\n",
    "    f_out = 'epoch {:4d} complete!'\n",
    "    print(f_out.format(epoch))\n",
    "    \n",
    "minimon.print_stats(as_minutes=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learnable-triangulation-pytorch",
   "language": "python",
   "name": "learnable-triangulation-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
