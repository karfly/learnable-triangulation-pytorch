{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "formed-george",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "annual-fireplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 3            |        cudaMalloc retries: 4         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |  290336 KB |    3779 MB |  133413 MB |  133130 MB |\n",
      "|       from large pool |  272384 KB |    3561 MB |  130334 MB |  130068 MB |\n",
      "|       from small pool |   17952 KB |     229 MB |    3078 MB |    3061 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |  290336 KB |    3779 MB |  133413 MB |  133130 MB |\n",
      "|       from large pool |  272384 KB |    3561 MB |  130334 MB |  130068 MB |\n",
      "|       from small pool |   17952 KB |     229 MB |    3078 MB |    3061 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |  587776 KB |    3834 MB |    3880 MB |    3306 MB |\n",
      "|       from large pool |  540672 KB |    3604 MB |    3642 MB |    3114 MB |\n",
      "|       from small pool |   47104 KB |     230 MB |     238 MB |     192 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |  297440 KB |  645583 KB |   97043 MB |   96752 MB |\n",
      "|       from large pool |  268288 KB |  612352 KB |   93650 MB |   93388 MB |\n",
      "|       from small pool |   29152 KB |   38947 KB |    3393 MB |    3364 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     253    |    2082    |   54950    |   54697    |\n",
      "|       from large pool |      41    |     555    |    7718    |    7677    |\n",
      "|       from small pool |     212    |    1528    |   47232    |   47020    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     253    |    2082    |   54950    |   54697    |\n",
      "|       from large pool |      41    |     555    |    7718    |    7677    |\n",
      "|       from small pool |     212    |    1528    |   47232    |   47020    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      32    |     187    |     192    |     160    |\n",
      "|       from large pool |       9    |      72    |      73    |      64    |\n",
      "|       from small pool |      23    |     115    |     119    |      96    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      76    |     147    |   31452    |   31376    |\n",
      "|       from large pool |       9    |      35    |    3348    |    3339    |\n",
      "|       from small pool |      67    |     121    |   28104    |   28037    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import shutil\n",
    "import argparse\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from itertools import islice\n",
    "import pickle\n",
    "import copy\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "from mvn.models.triangulation import RANSACTriangulationNet, AlgebraicTriangulationNet, VolumetricTriangulationNet\n",
    "from mvn.models.loss import KeypointsMSELoss, KeypointsMSESmoothLoss, KeypointsMAELoss, KeypointsL2Loss, VolumetricCELoss, element_weighted_loss\n",
    "\n",
    "from mvn.utils import img, multiview, op, vis, misc, cfg\n",
    "from mvn.datasets import human36m\n",
    "from mvn.datasets import utils as dataset_utils\n",
    "from mvn.utils.multiview import project_3d_points_to_image_plane_without_distortion\n",
    "\n",
    "from mvn.utils.minimon import MiniMon\n",
    "from mvn.utils.misc import normalize_transformation, flush_cache\n",
    "from mvn.utils.dicts import NestedNamespace\n",
    "\n",
    "from train import setup_dataloaders, setup_experiment\n",
    "\n",
    "\n",
    "flush_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "latter-advance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# available GPUs: 1\n",
      "estimating dataset size ...\n",
      "  ... available subjects ['S1', 'S6', 'S7', 'S8'] and subsampling 1/10000 => 12 available frames\n",
      "estimating dataset size ...\n",
      "  ... available subjects ['S9', 'S11'] and subsampling 1/10 => 219 available frames\n",
      "  training dataset length: 12\n",
      "  validation dataset length: 5\n"
     ]
    }
   ],
   "source": [
    "def get_args():\n",
    "    args = NestedNamespace(\n",
    "        dict(\n",
    "            config='experiments/human36m/train/human36m_alg.yaml',\n",
    "            eval=False,\n",
    "            eval_dataset='val',\n",
    "            local_rank=None, logdir='/home/stefano/_tmp/logs',\n",
    "            seed=42\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print('# available GPUs: {:d}'.format(torch.cuda.device_count()))\n",
    "    \n",
    "    return args\n",
    "\n",
    "\n",
    "def get_config(args):\n",
    "    config = cfg.load_config(args.config)\n",
    "\n",
    "    config.image_shape = [128, 128]\n",
    "    config.debug.write_imgs = True\n",
    "    config.debug.img_out = '/home/stefano/_tmp/logs/imgs'\n",
    "    config.debug.dump_checkpoints = False\n",
    "\n",
    "    config.opt.n_epochs = 2\n",
    "    config.opt.n_iters_per_epoch = config.opt.n_objects_per_epoch // config.opt.batch_size\n",
    "    \n",
    "    config.opt.torch_anomaly_detection = False\n",
    "\n",
    "    config.opt.batch_size = 8\n",
    "    config.opt.val_batch_size = 16\n",
    "\n",
    "    data_folder = '/home/stefano/_tmp/data/'\n",
    "\n",
    "    config.model.triangulate_in_world_space = False  # in cam space\n",
    "    config.model.init_weights = False  # there is no point in loading full module with a shitty GPU\n",
    "    config.model.checkpoint = data_folder + 'weights_alg.pth'  #  + 'weights_vol.pth'\n",
    "    config.model.backbone.checkpoint = data_folder + 'pose_resnet_4.5_pixels_human36m.pth'\n",
    "    config.model.backbone.init_weights = config.model.init_weights\n",
    "    config.model.backbone.num_layers = 18  # very small BB\n",
    "    config.model.backbone.num_deconv_filters = 32\n",
    "\n",
    "    config.dataset.train.h36m_root = data_folder + 'processed/'\n",
    "    config.dataset.train.labels_path = data_folder + 'human36m-multiview-labels-GTbboxes.npy'\n",
    "    config.dataset.train.retain_every_n_frames_in_train = 10000  # 12 images when in full dataset\n",
    "    config.dataset.train.num_workers = 0\n",
    "\n",
    "    config.dataset.val.h36m_root = config.dataset.train.h36m_root  # the same! WTF!\n",
    "    config.dataset.val.labels_path = config.dataset.train.labels_path  # the same! WTF!\n",
    "    config.dataset.val.retain_every_n_frames_in_test = 500  # 5 images when in full dataset\n",
    "    config.dataset.val.num_workers = 0\n",
    "    \n",
    "    return config\n",
    "\n",
    "\n",
    "def build_labels(f_path, retain_every_n_frames, allowed_subjects=['S1', 'S6', 'S7', 'S8']):\n",
    "    print('estimating dataset size ...')\n",
    "    labels = np.load(f_path, allow_pickle=True).item()\n",
    "    \n",
    "    subjects = [\n",
    "        labels['subject_names'].index(x)\n",
    "        for x in allowed_subjects  # todo solve missing images in 'S5'\n",
    "    ]\n",
    "    \n",
    "    mask = np.isin(labels['table']['subject_idx'], subjects, assume_unique=True)\n",
    "    indices = np.nonzero(mask)[0][::retain_every_n_frames]\n",
    "    \n",
    "    print('  ... available subjects {} and subsampling 1/{:d} => {:d} available frames'.format(\n",
    "        allowed_subjects,\n",
    "        retain_every_n_frames,\n",
    "        len(indices)\n",
    "    ))\n",
    "    \n",
    "    return labels, mask, indices\n",
    "\n",
    "\n",
    "def build_env(config, device):\n",
    "    model = {\n",
    "        \"ransac\": RANSACTriangulationNet,\n",
    "        \"alg\": AlgebraicTriangulationNet,\n",
    "        \"vol\": VolumetricTriangulationNet\n",
    "    }[config.model.name](config, device=device).to(device)\n",
    "\n",
    "    if config.model.init_weights:\n",
    "        state_dict = torch.load(config.model.checkpoint)\n",
    "        for key in list(state_dict.keys()):\n",
    "            new_key = key.replace(\"module.\", \"\")\n",
    "            state_dict[new_key] = state_dict.pop(key)\n",
    "\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "        print('Successfully loaded pretrained weights for whole model')\n",
    "    \n",
    "    criterion_class = {\n",
    "        \"MSE\": KeypointsMSELoss,\n",
    "        \"MSESmooth\": KeypointsMSESmoothLoss,\n",
    "        \"MAE\": KeypointsMAELoss\n",
    "    }[config.opt.criterion]\n",
    "\n",
    "    if config.opt.criterion == \"MSESmooth\":\n",
    "        criterion = criterion_class(config.opt.mse_smooth_threshold)\n",
    "    else:\n",
    "        criterion = criterion_class()\n",
    "\n",
    "    if config.model.name == \"vol\":\n",
    "        opt = torch.optim.Adam(\n",
    "            [\n",
    "                {\n",
    "                    'params': model.backbone.parameters()\n",
    "                },\n",
    "                {\n",
    "                    'params': model.process_features.parameters(),\n",
    "                    'lr': config.opt.process_features_lr if hasattr(config.opt, \"process_features_lr\") else config.opt.lr\n",
    "                },\n",
    "                {\n",
    "                    'params': model.volume_net.parameters(),\n",
    "                    'lr': config.opt.volume_net_lr if hasattr(config.opt, \"volume_net_lr\") else config.opt.lr\n",
    "                }\n",
    "            ],\n",
    "            lr=config.opt.lr\n",
    "        )\n",
    "    else:\n",
    "        opt = optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            lr=config.opt.lr\n",
    "        )\n",
    "    \n",
    "    return model, criterion, opt\n",
    "\n",
    "\n",
    "is_distributed = False\n",
    "master = True\n",
    "device = torch.device(0)\n",
    "    \n",
    "args = get_args()\n",
    "config = get_config(args)\n",
    "model, criterion, opt = build_env(config, torch.device(0))\n",
    "labels, mask, indices = build_labels(config.dataset.train.labels_path, 10000)\n",
    "labels, mask, indices = build_labels(config.dataset.train.labels_path, 10, allowed_subjects=['S9', 'S11'])\n",
    "\n",
    "train_dataloader, val_dataloader, train_sampler = setup_dataloaders(config, distributed_train=is_distributed)  # ~ 0 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "dedicated-speech",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0 has started!\n",
      "  batch iter 0 loss ~ 278.083\n",
      "  batch iter 1 loss ~ 274.504\n",
      "epoch    1 complete!\n",
      "epoch    1 has started!\n",
      "  batch iter 0 loss ~ 271.595\n",
      "  batch iter 1 loss ~ 276.565\n",
      "epoch    2 complete!\n",
      "           calc loss x          4 ~        0.0 [min:        0.0,    max:        0.0,    last:        0.0]\n",
      "       alg: backbone x          4 ~        0.0 [min:        0.0,    max:        0.0,    last:        0.0]\n",
      "lg: tri in cam space x          4 ~        0.0 [min:        0.0,    max:        0.0,    last:        0.0]\n",
      "        forward pass x          4 ~        0.0 [min:        0.0,    max:        0.0,    last:        0.0]\n",
      "       backward pass x          4 ~        0.1 [min:        0.0,    max:        0.1,    last:        0.0]\n",
      "ad first train batch x          2 ~        0.5 [min:        0.5,    max:        0.6,    last:        0.5]\n",
      "         train epoch x          2 ~        6.4 [min:        6.4,    max:        6.5,    last:        6.4]\n",
      "    all times are in seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from train import one_epoch\n",
    "\n",
    "minimon = MiniMon()\n",
    "for epoch in range(config.opt.n_epochs):\n",
    "    # cannot use train_sampler.set_epoch since we're not distributed !\n",
    "    \n",
    "    f_out = 'epoch {:4d} has started!'\n",
    "    print(f_out.format(epoch))\n",
    "\n",
    "    minimon.enter()\n",
    "    one_epoch(model, criterion, opt, config, train_dataloader, device, epoch, minimon, is_train=True, master=master)\n",
    "    minimon.leave('train epoch')\n",
    "\n",
    "    # minimon.enter()\n",
    "    # one_epoch(model, criterion, opt, config, val_dataloader, device, epoch, minimon, is_train=False, master=master)\n",
    "    # minimon.leave('eval epoch')\n",
    "\n",
    "    f_out = 'epoch {:4d} complete!'\n",
    "    print(f_out.format(epoch + 1))\n",
    "    \n",
    "minimon.print_stats(as_minutes=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learnable-triangulation-pytorch",
   "language": "python",
   "name": "learnable-triangulation-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
