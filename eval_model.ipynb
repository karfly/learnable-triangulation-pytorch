{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "raised-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "annual-fireplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import shutil\n",
    "import argparse\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from itertools import islice\n",
    "import pickle\n",
    "import copy\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "from mvn.models.triangulation import RANSACTriangulationNet, AlgebraicTriangulationNet, VolumetricTriangulationNet\n",
    "from mvn.models.loss import KeypointsMSELoss, KeypointsMSESmoothLoss, KeypointsMAELoss, KeypointsL2Loss, VolumetricCELoss, element_weighted_loss\n",
    "\n",
    "from mvn.utils import img, multiview, op, vis, misc, cfg\n",
    "from mvn.datasets import human36m\n",
    "from mvn.datasets import utils as dataset_utils\n",
    "from mvn.utils.multiview import project_3d_points_to_image_plane_without_distortion\n",
    "\n",
    "from mvn.utils.minimon import MiniMon\n",
    "from mvn.utils.misc import normalize_transformation, flush_cache\n",
    "from mvn.utils.dicts import NestedNamespace\n",
    "\n",
    "from train import setup_dataloaders, setup_experiment\n",
    "\n",
    "flush_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "latter-advance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# available GPUs: 1\n",
      "  training dataset length: 12\n",
      "  validation dataset length: 5\n"
     ]
    }
   ],
   "source": [
    "def get_args():\n",
    "    args = NestedNamespace(\n",
    "        dict(\n",
    "            config='experiments/human36m/train/human36m_alg.yaml',\n",
    "            eval=False,\n",
    "            eval_dataset='val',\n",
    "            local_rank=None, logdir='/home/stefano/_tmp/logs',\n",
    "            seed=42\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print('# available GPUs: {:d}'.format(torch.cuda.device_count()))\n",
    "    \n",
    "    return args\n",
    "\n",
    "\n",
    "def get_config(args):\n",
    "    config = cfg.load_config(args.config)\n",
    "\n",
    "    config.image_shape = [128, 128]\n",
    "    config.debug.write_imgs = True\n",
    "    config.debug.dump_checkpoints = False\n",
    "\n",
    "    config.opt.n_epochs = 2\n",
    "    config.opt.n_iters_per_epoch = config.opt.n_objects_per_epoch // config.opt.batch_size\n",
    "\n",
    "    config.opt.batch_size = 8\n",
    "    config.opt.val_batch_size = 16\n",
    "\n",
    "    data_folder = '/home/stefano/_tmp/data/'\n",
    "\n",
    "    config.model.init_weights = False  # there is no point in loading full module with a shitty GPU\n",
    "    config.model.checkpoint = data_folder + 'weights_alg.pth'  #  + 'weights_vol.pth'\n",
    "    config.model.backbone.checkpoint = data_folder + 'pose_resnet_4.5_pixels_human36m.pth'\n",
    "    config.model.backbone.init_weights = config.model.init_weights\n",
    "    config.model.backbone.num_layers = 18  # very small BB\n",
    "    config.model.backbone.num_deconv_filters = 32\n",
    "\n",
    "    config.dataset.train.h36m_root = data_folder + 'processed/'\n",
    "    config.dataset.train.labels_path = data_folder + 'human36m-multiview-labels-GTbboxes.npy'\n",
    "    config.dataset.train.retain_every_n_frames_in_train = 10000  # 12 images when in full dataset\n",
    "    config.dataset.train.num_workers = 0\n",
    "\n",
    "    config.dataset.val.h36m_root = config.dataset.train.h36m_root  # the same! WTF!\n",
    "    config.dataset.val.labels_path = config.dataset.train.labels_path  # the same! WTF!\n",
    "    config.dataset.val.retain_every_n_frames_in_test = 500  # 5 images when in full dataset\n",
    "    config.dataset.val.num_workers = 0\n",
    "    \n",
    "    return config\n",
    "\n",
    "\n",
    "def build_env(config, device):\n",
    "    model = {\n",
    "        \"ransac\": RANSACTriangulationNet,\n",
    "        \"alg\": AlgebraicTriangulationNet,\n",
    "        \"vol\": VolumetricTriangulationNet\n",
    "    }[config.model.name](config, device=device).to(device)\n",
    "\n",
    "    if config.model.init_weights:\n",
    "        state_dict = torch.load(config.model.checkpoint)\n",
    "        for key in list(state_dict.keys()):\n",
    "            new_key = key.replace(\"module.\", \"\")\n",
    "            state_dict[new_key] = state_dict.pop(key)\n",
    "\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "        print('Successfully loaded pretrained weights for whole model')\n",
    "    \n",
    "    criterion_class = {\n",
    "        \"MSE\": KeypointsMSELoss,\n",
    "        \"MSESmooth\": KeypointsMSESmoothLoss,\n",
    "        \"MAE\": KeypointsMAELoss\n",
    "    }[config.opt.criterion]\n",
    "\n",
    "    if config.opt.criterion == \"MSESmooth\":\n",
    "        criterion = criterion_class(config.opt.mse_smooth_threshold)\n",
    "    else:\n",
    "        criterion = criterion_class()\n",
    "\n",
    "    if config.model.name == \"vol\":\n",
    "        opt = torch.optim.Adam(\n",
    "            [\n",
    "                {\n",
    "                    'params': model.backbone.parameters()\n",
    "                },\n",
    "                {\n",
    "                    'params': model.process_features.parameters(),\n",
    "                    'lr': config.opt.process_features_lr if hasattr(config.opt, \"process_features_lr\") else config.opt.lr\n",
    "                },\n",
    "                {\n",
    "                    'params': model.volume_net.parameters(),\n",
    "                    'lr': config.opt.volume_net_lr if hasattr(config.opt, \"volume_net_lr\") else config.opt.lr\n",
    "                }\n",
    "            ],\n",
    "            lr=config.opt.lr\n",
    "        )\n",
    "    else:\n",
    "        opt = optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            lr=config.opt.lr\n",
    "        )\n",
    "    \n",
    "    return model, criterion, opt\n",
    "\n",
    "\n",
    "is_distributed = False\n",
    "master = True\n",
    "device = torch.device(0)\n",
    "    \n",
    "args = get_args()\n",
    "config = get_config(args)\n",
    "model, criterion, opt = build_env(config, torch.device(0))\n",
    "\n",
    "train_dataloader, val_dataloader, train_sampler = setup_dataloaders(config, distributed_train=is_distributed)  # ~ 0 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "confidential-cargo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================== epoch    1 complete!\n",
      "================================================== epoch    2 complete!\n",
      "       alg: backbone x          4 ~        0.0 [       0.0,        0.1]\n",
      "           calc loss x          4 ~        0.1 [       0.1,        0.2]\n",
      "       backward pass x          4 ~        0.2 [       0.1,        0.2]\n",
      "ad first train batch x          2 ~        0.4 [       0.4,        0.4]\n",
      "     alg: tri in CPU x          4 ~        0.8 [       0.5,        1.0]\n",
      "    alg: triangulate x          4 ~        0.8 [       0.5,        1.0]\n",
      "        forward pass x          4 ~        0.8 [       0.5,        1.1]\n",
      "         train epoch x          2 ~        3.1 [       3.0,        3.1]\n",
      "    all times are in seconds\n"
     ]
    }
   ],
   "source": [
    "from train import one_epoch\n",
    "\n",
    "minimon = MiniMon()\n",
    "for epoch in range(config.opt.n_epochs):\n",
    "    # cannot use train_sampler.set_epoch since we're not distributed !\n",
    "\n",
    "    minimon.enter()\n",
    "    one_epoch(model, criterion, opt, config, train_dataloader, device, epoch, minimon, is_train=True, master=master)\n",
    "    minimon.leave('train epoch')\n",
    "\n",
    "    # minimon.enter()\n",
    "    # one_epoch(model, criterion, opt, config, val_dataloader, device, epoch, minimon, is_train=False, master=master)\n",
    "    # minimon.leave('eval epoch')\n",
    "\n",
    "    f_out = '=' * 50 + ' epoch {:4d} complete!'\n",
    "    print(f_out.format(epoch + 1))\n",
    "    \n",
    "minimon.print_stats(as_minutes=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learnable-triangulation-pytorch",
   "language": "python",
   "name": "learnable-triangulation-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
