{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "formed-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "annual-fireplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import shutil\n",
    "import argparse\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from itertools import islice\n",
    "import pickle\n",
    "import copy\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "from mvn.models.triangulation import RANSACTriangulationNet, AlgebraicTriangulationNet, VolumetricTriangulationNet\n",
    "from mvn.models.loss import KeypointsMSELoss, KeypointsMSESmoothLoss, KeypointsMAELoss, KeypointsL2Loss, VolumetricCELoss, element_weighted_loss\n",
    "\n",
    "from mvn.utils import img, multiview, op, vis, misc, cfg\n",
    "from mvn.datasets import human36m\n",
    "from mvn.datasets import utils as dataset_utils\n",
    "from mvn.utils.multiview import project_3d_points_to_image_plane_without_distortion\n",
    "\n",
    "from mvn.utils.minimon import MiniMon\n",
    "from mvn.utils.misc import normalize_transformation, flush_cache\n",
    "from mvn.utils.dicts import NestedNamespace\n",
    "\n",
    "from train import setup_dataloaders, setup_experiment\n",
    "\n",
    "\n",
    "flush_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "latter-advance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# available GPUs: 1\n",
      "estimating dataset size ...\n",
      "  ... available subjects ['S1', 'S6', 'S7', 'S8'] and subsampling 1/10000 => 12 available frames\n",
      "estimating dataset size ...\n",
      "  ... available subjects ['S9', 'S11'] and subsampling 1/100 => 22 available frames\n",
      "  training dataset length: 12\n",
      "  validation dataset length: 5\n"
     ]
    }
   ],
   "source": [
    "def get_args():\n",
    "    args = NestedNamespace(\n",
    "        dict(\n",
    "            config='experiments/human36m/train/human36m_alg.yaml',\n",
    "            eval=False,\n",
    "            eval_dataset='val',\n",
    "            local_rank=None, logdir='/home/stefano/_tmp/logs',\n",
    "            seed=42\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print('# available GPUs: {:d}'.format(torch.cuda.device_count()))\n",
    "    \n",
    "    return args\n",
    "\n",
    "\n",
    "def get_config(args):\n",
    "    config = cfg.load_config(args.config)\n",
    "\n",
    "    config.image_shape = [128, 128]\n",
    "    config.debug.write_imgs = True\n",
    "    config.debug.img_out = '/home/stefano/_tmp/logs/imgs'\n",
    "    config.debug.dump_checkpoints = False\n",
    "\n",
    "    config.opt.n_epochs = 2\n",
    "    config.opt.n_iters_per_epoch = config.opt.n_objects_per_epoch // config.opt.batch_size\n",
    "    \n",
    "    config.opt.torch_anomaly_detection = False\n",
    "\n",
    "    config.opt.loss_3d = False\n",
    "    config.opt.loss_2d = not config.opt.loss_3d\n",
    "    config.opt.batch_size = 8\n",
    "    config.opt.val_batch_size = 16\n",
    "\n",
    "    data_folder = '/home/stefano/_tmp/data/'\n",
    "\n",
    "    config.model.triangulate_in_world_space = False\n",
    "    config.model.triangulate_in_cam_space = False\n",
    "    config.model.cam2cam_estimation = True\n",
    "    config.model.init_weights = False  # there is no point in loading full module with a shitty GPU\n",
    "    config.model.checkpoint = data_folder + 'weights_alg.pth'  #  + 'weights_vol.pth'\n",
    "    config.model.backbone.checkpoint = data_folder + 'pose_resnet_4.5_pixels_human36m.pth'\n",
    "    config.model.backbone.init_weights = config.model.init_weights\n",
    "    config.model.backbone.num_layers = 18  # very small BB\n",
    "    config.model.backbone.num_deconv_filters = 32\n",
    "\n",
    "    config.dataset.train.h36m_root = data_folder + 'processed/'\n",
    "    config.dataset.train.labels_path = data_folder + 'human36m-multiview-labels-GTbboxes.npy'\n",
    "    config.dataset.train.retain_every_n_frames_in_train = 10000  # 12 images when in full dataset\n",
    "    config.dataset.train.num_workers = 1\n",
    "\n",
    "    config.dataset.val.h36m_root = config.dataset.train.h36m_root  # the same! WTF!\n",
    "    config.dataset.val.labels_path = config.dataset.train.labels_path  # the same! WTF!\n",
    "    config.dataset.val.retain_every_n_frames_in_test = 500  # 5 images when in full dataset\n",
    "    config.dataset.val.num_workers = 1\n",
    "    \n",
    "    return config\n",
    "\n",
    "\n",
    "def build_labels(f_path, retain_every_n_frames, allowed_subjects=['S1', 'S6', 'S7', 'S8']):\n",
    "    print('estimating dataset size ...')\n",
    "    labels = np.load(f_path, allow_pickle=True).item()\n",
    "    \n",
    "    subjects = [\n",
    "        labels['subject_names'].index(x)\n",
    "        for x in allowed_subjects  # todo solve missing images in 'S5'\n",
    "    ]\n",
    "    \n",
    "    mask = np.isin(labels['table']['subject_idx'], subjects, assume_unique=True)\n",
    "    indices = np.nonzero(mask)[0][::retain_every_n_frames]\n",
    "    \n",
    "    print('  ... available subjects {} and subsampling 1/{:d} => {:d} available frames'.format(\n",
    "        allowed_subjects,\n",
    "        retain_every_n_frames,\n",
    "        len(indices)\n",
    "    ))\n",
    "    \n",
    "    return labels, mask, indices\n",
    "\n",
    "\n",
    "def build_env(config, device):\n",
    "    model = {\n",
    "        \"ransac\": RANSACTriangulationNet,\n",
    "        \"alg\": AlgebraicTriangulationNet,\n",
    "        \"vol\": VolumetricTriangulationNet\n",
    "    }[config.model.name](config, device=device).to(device)\n",
    "\n",
    "    if config.model.init_weights:\n",
    "        state_dict = torch.load(config.model.checkpoint)\n",
    "        for key in list(state_dict.keys()):\n",
    "            new_key = key.replace(\"module.\", \"\")\n",
    "            state_dict[new_key] = state_dict.pop(key)\n",
    "\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "        print('Successfully loaded pretrained weights for whole model')\n",
    "    \n",
    "    criterion_class = {\n",
    "        \"MSE\": KeypointsMSELoss,\n",
    "        \"MSESmooth\": KeypointsMSESmoothLoss,\n",
    "        \"MAE\": KeypointsMAELoss\n",
    "    }[config.opt.criterion]\n",
    "\n",
    "    if config.opt.criterion == \"MSESmooth\":\n",
    "        criterion = criterion_class(config.opt.mse_smooth_threshold)\n",
    "    else:\n",
    "        criterion = criterion_class()\n",
    "\n",
    "    if config.model.name == \"vol\":\n",
    "        opt = torch.optim.Adam(\n",
    "            [\n",
    "                {\n",
    "                    'params': model.backbone.parameters()\n",
    "                },\n",
    "                {\n",
    "                    'params': model.process_features.parameters(),\n",
    "                    'lr': config.opt.process_features_lr if hasattr(config.opt, \"process_features_lr\") else config.opt.lr\n",
    "                },\n",
    "                {\n",
    "                    'params': model.volume_net.parameters(),\n",
    "                    'lr': config.opt.volume_net_lr if hasattr(config.opt, \"volume_net_lr\") else config.opt.lr\n",
    "                }\n",
    "            ],\n",
    "            lr=config.opt.lr\n",
    "        )\n",
    "    else:\n",
    "        opt = optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, model.parameters()),\n",
    "            lr=config.opt.lr\n",
    "        )\n",
    "    \n",
    "    return model, criterion, opt\n",
    "\n",
    "\n",
    "is_distributed = False\n",
    "master = True\n",
    "device = torch.device(0)\n",
    "    \n",
    "args = get_args()\n",
    "config = get_config(args)\n",
    "model, criterion, opt = build_env(config, torch.device(0))\n",
    "labels, mask, indices = build_labels(config.dataset.train.labels_path, 10000)\n",
    "labels, mask, indices = build_labels(config.dataset.train.labels_path, 100, allowed_subjects=['S9', 'S11'])\n",
    "\n",
    "train_dataloader, val_dataloader, train_sampler = setup_dataloaders(config, distributed_train=is_distributed)  # ~ 0 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dedicated-speech",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0 has started!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d226d999ff78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mminimon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mone_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaster\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mminimon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/scratch/learnable-triangulation-pytorch/train.py\u001b[0m in \u001b[0;36mone_epoch\u001b[0;34m(model, criterion, opt, config, dataloader, device, epoch, minimon, is_train, master, experiment_dir)\u001b[0m\n\u001b[1;32m    525\u001b[0m                     )\n\u001b[1;32m    526\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                 results_pred = iter_batch(\n\u001b[0m\u001b[1;32m    528\u001b[0m                     \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 )\n",
      "\u001b[0;32m~/scratch/learnable-triangulation-pytorch/train.py\u001b[0m in \u001b[0;36miter_batch\u001b[0;34m(batch, iter_i, model, model_type, criterion, opt, config, dataloader, device, epoch, minimon, is_train)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcam2cam_estimation\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# predict cam2cam matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m         results = cam2cam_iter(\n\u001b[0m\u001b[1;32m    482\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminimon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         )\n",
      "\u001b[0;32m~/scratch/learnable-triangulation-pytorch/train.py\u001b[0m in \u001b[0;36mcam2cam_iter\u001b[0;34m(batch, iter_i, model, model_type, criterion, opt, images_batch, is_train, config, minimon)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpair_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mpair_of_pose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_i\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# ~ (2, n_joints=17, 2D)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             cam2cam_preds[batch_i, pair_i] = Roto6d(\n\u001b[0m\u001b[1;32m    404\u001b[0m                 \u001b[0mpair_of_pose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# todo with heatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             )\n",
      "\u001b[0;32m~/scratch/learnable-triangulation-pytorch/mvn/models/rototrans.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, using_conv, n_params)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0musing_conv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m  \u001b[0;31m# todo, then expecting as input some heatmaps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "from train import one_epoch\n",
    "\n",
    "minimon = MiniMon()\n",
    "for epoch in range(config.opt.n_epochs):\n",
    "    # cannot use train_sampler.set_epoch since we're not distributed !\n",
    "    \n",
    "    f_out = 'epoch {:4d} has started!'\n",
    "    print(f_out.format(epoch))\n",
    "\n",
    "    minimon.enter()\n",
    "    one_epoch(model, criterion, opt, config, train_dataloader, device, epoch, minimon, is_train=True, master=master)\n",
    "    minimon.leave('train epoch')\n",
    "\n",
    "    minimon.enter()\n",
    "    one_epoch(model, criterion, opt, config, val_dataloader, device, epoch, minimon, is_train=False, master=master)\n",
    "    minimon.leave('eval epoch')\n",
    "\n",
    "    f_out = 'epoch {:4d} complete!'\n",
    "    print(f_out.format(epoch))\n",
    "    \n",
    "minimon.print_stats(as_minutes=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learnable-triangulation-pytorch",
   "language": "python",
   "name": "learnable-triangulation-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
